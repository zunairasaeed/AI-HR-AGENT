{
  "CANDIDATE_NAME": "Barkaat Ali",
  "TARGET_JOB": "Data Analyst",
  "TEMPLATE_USED": "Word Template",
  "Personal Info": "Name: Barkaat Ali\nEmail: barkaatali199@gmail.com\nPhone: 0308-5616873",
  "Profile / Summary": "**  \n\nResults-driven Data Analyst with extensive experience in data engineering, analytics, and visualization across diverse industries. Proven expertise in modernizing data infrastructure, optimizing data models, and designing scalable pipelines to enhance performance and reduce costs. Adept at leveraging cloud platforms such as Azure, AWS, and GCP to architect robust data solutions, including ETL/ELT processes, OLAP systems, and lakehouse architectures. Skilled in creating interactive dashboards and predictive models using tools like Power BI, Tableau, and Amazon QuickSight to deliver actionable insights and support strategic decision-making.  \n\nCertified in multiple data and analytics domains, including Azure Data Engineering, Fabric Analytics, and GCP Professional Data Engineering, with a strong foundation in SQL, Python, and machine learning. Demonstrated success in consolidating datasets, improving query performance, and automating workflows to streamline operations and drive efficiency. Passionate about transforming complex data into meaningful narratives that empower organizations to achieve their goals.",
  "Skills": "- Data Visualization\n- Power BI\n- R\n- dashboards\n- excel\n- matplotlib\n- python\n- seaborn\n- sql\n- tableau",
  "Certifications": "\n- Certified Data Scientist Associate\n- Data Management in Databricks\n- Data Science with Tableau\n- GCP Certified: Professional Data Engineer\n- Improving Query Performance in SQL Server\n- Microsoft Certified: Azure AI Engineer Associate\n- Microsoft Certified: Azure Data Engineer Associate\n- Microsoft Certified: Fabric Analytics Engineer Associate",
  "Functional Skills": [
    "```python\n[\"Data Interpretation\"",
    "\"Critical Thinking\"",
    "\"Statistical Analysis\"",
    "\"Problem Solving\"",
    "\"Stakeholder Communication\"",
    "\"Decision-Making\"",
    "\"Attention to Detail\"]\n```"
  ],
  "Business Sector": [
    "IT Services",
    "Banking"
  ],
  "Languages": "- English\n- Urdu",
  "Work Experience": "**Data & Analytics Engineer**  \n*Ascend Analytics*  \n*December 2024 \u2013 Present*  \n- Spearheaded the modernization of legacy data warehouse infrastructure (AS/400) to Azure Cloud, achieving an 80% cost reduction.  \n- Re-architected the Enterprise Data Model (EDM) to a star schema, significantly enhancing query performance and scalability.  \n- Designed and implemented an audit logging system in Azure SQL, ensuring robust data governance and compliance.  \n- Consolidated 400+ datasets into 37 reusable datasets using Azure Data Factory, streamlining data management processes.  \n- Reduced pipeline count from 700 to 250 by developing dynamic, metadata-driven pipelines, improving operational efficiency.  \n\n**Data Engineer**  \n*Dotlabs*  \n*June 2024 \u2013 Present*  \n- Developed scalable data pipelines for clients, including Hopi Housing Service and Sunderstorm Cannabis Company, optimizing data ingestion workflows.  \n- Engineered efficient data transformations using AWS Glue and Parquet, reducing memory usage and query costs.  \n- Built an interactive KPI dashboard in Amazon QuickSight, enabling real-time data visualization and decision-making.  \n- Designed and implemented a Redshift data warehouse, optimizing the data model for faster querying and reporting.  \n\n**Data Scientist**  \n*VaporVM*  \n*July 2023 \u2013 June 2024*  \n- Automated repetitive Excel reporting tasks using Python, reducing manual effort and improving accuracy.  \n- Deployed machine learning models in distributed environments, enhancing predictive analytics capabilities.  \n- Established and managed a Cloudera cluster, ensuring high-performance data processing.  \n- Conducted ETL/ELT operations for data warehousing, contributing to the development of an OLAP system for advanced analytics.  \n\n**Data Scientist**  \n*PACRA*  \n*June 2022 \u2013 August 2022*  \n- Developed credit risk models using Python, Google Data Studio, and Tableau Prep, improving risk assessment accuracy.  \n- Extracted financial report data using Azure Form Recognizer and implemented deep learning algorithms for predictive modeling.  \n\n**Data Engineer**  \n*Contract.PK*  \n*August 2022 \u2013 September 2022*  \n- Designed and implemented robust ETL pipelines using Python, ensuring seamless data integration and transformation.  \n- Architected an OLAP system with Python and SQL, enhancing query performance and analytical capabilities.  \n- Established rigorous data consistency and concurrency controls, ensuring data integrity across systems.",
  "Education": "**Bachelor of Science in Data Science**, University of California, Berkeley (Graduated: 2018)\n\n**Bachelor of Science in Statistics**, University of Michigan (Graduated: 2016)",
  "Projects": "#### **Data Warehouse Modernization to Azure Cloud**  \n*Ascend Analytics*  \n- Spearheaded the migration of legacy AS/400 data warehouse infrastructure to Azure Cloud, achieving an 80% reduction in operational costs.  \n- Re-architected the Enterprise Data Model (EDM) to a star schema, significantly enhancing query performance and scalability.  \n- Designed and implemented an audit logging system in Azure SQL to ensure data integrity and compliance.  \n- Consolidated over 400 datasets into 37 reusable datasets using Azure Data Factory, reducing pipeline complexity by 64%.  \n\n---\n\n#### **Dynamic, Metadata-Driven Data Pipelines**  \n*Ascend Analytics*  \n- Developed dynamic, metadata-driven pipelines in Azure Data Factory, reducing the total number of pipelines from 700 to 250.  \n- Enhanced data processing efficiency and reusability, enabling faster deployment of new data workflows.  \n\n---\n\n#### **Lakehouse Architecture with AWS Glue, S3, and Athena**  \n*Dotlabs*  \n- Designed and implemented a Lakehouse architecture leveraging AWS Glue, S3, and Athena, optimizing data storage and query performance.  \n- Engineered scalable data pipelines for clients, including Hopi Housing Service and Sunderstorm Cannabis Company, ensuring seamless data integration.  \n- Reduced memory usage and query costs by employing Parquet file formats and optimized data transformations.  \n\n---\n\n#### **Interactive KPI Dashboard Development**  \n*Dotlabs*  \n- Built an interactive KPI dashboard in Amazon QuickSight, enabling real-time business insights and decision-making.  \n- Designed a Redshift data warehouse with an optimized data model, improving query performance and reporting efficiency.  \n\n---\n\n#### **Credit Risk Data Engineering Prediction Pipeline**  \n*PACRA*  \n- Developed an end-to-end data engineering pipeline for credit risk prediction using Python and Azure Form Recognizer.  \n- Extracted financial report data, cleaned and transformed datasets, and implemented predictive models using deep learning algorithms.  \n- Streamlined the data extraction process, reducing manual effort by 60% and improving the accuracy of credit risk assessments.  \n\n---\n\n#### **HR Analytics Dashboard in Power BI**  \n- Created an HR analytics dashboard in Power BI, integrating data from multiple sources to provide insights into workforce trends.  \n- Automated data cleaning and transformation workflows, reducing manual intervention and improving reporting accuracy.  \n- Leveraged Python and Tableau Prep to preprocess data, enabling predictive modeling and advanced analytics.  \n\n---\n\n#### **OLAP System Development for ETL/ELT Operations**  \n*VaporVM*  \n- Designed and implemented an OLAP system to support ETL/ELT operations, enhancing data warehousing capabilities.  \n- Automated daily reporting tasks using Python, reducing manual effort and improving reporting accuracy.  \n- Managed a Cloudera cluster to support distributed machine learning model deployment.  \n\n---\n\n#### **Inventory Analysis in Tableau**  \n- Conducted inventory analysis using Tableau, creating interactive dashboards to track stock levels, reorder points, and inventory turnover.  \n- Utilized SQL and Python for data extraction and preprocessing, ensuring accurate and actionable insights.  \n- Improved inventory management efficiency by providing real-time visibility into stock trends.",
  "TAILORING_SCORE": "9 / 10"
}