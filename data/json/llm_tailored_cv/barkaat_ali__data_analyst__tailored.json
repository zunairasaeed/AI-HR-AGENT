{
  "CANDIDATE_NAME": "Barkaat Ali",
  "TARGET_JOB": "Data Analyst",
  "TEMPLATE_USED": "Word Template",
  "Personal Info": "Name: Barkaat Ali\nEmail: barkaatali199@gmail.com\nPhone: 0308-5616873",
  "Profile": "**  \nResults-driven Data Analyst with extensive experience in data engineering, analytics, and visualization across diverse industries. Proven expertise in modernizing data infrastructure, optimizing query performance, and developing scalable pipelines using cutting-edge technologies such as Azure, AWS, and Python. Adept at transforming complex datasets into actionable insights through interactive dashboards and predictive models, leveraging tools like Tableau, Power BI, and Amazon QuickSight. Skilled in implementing machine learning algorithms, enhancing data governance, and architecting robust data warehouses to support strategic decision-making. Certified in Azure, GCP, and Databricks, with a strong commitment to delivering cost-effective and scalable solutions that drive business growth.",
  "Skills": "- Data Visualization\n- Power BI\n- R\n- dashboards\n- excel\n- matplotlib\n- python\n- seaborn\n- sql\n- tableau",
  "Certifications": "\n- Certified Data Scientist Associate\n- Data Management in Databricks\n- Data Science with Tableau\n- GCP Certified: Professional Data Engineer\n- Improving Query Performance in SQL Server\n- Microsoft Certified: Azure AI Engineer Associate\n- Microsoft Certified: Azure Data Engineer Associate\n- Microsoft Certified: Fabric Analytics Engineer Associate",
  "Functional Skills": [
    "```python\n[\"Data Interpretation\"",
    "\"Critical Thinking\"",
    "\"Statistical Analysis\"",
    "\"Problem Solving\"",
    "\"Stakeholder Communication\"",
    "\"Decision Making\"",
    "\"Attention to Detail\"]\n```"
  ],
  "Business Sector": [
    "IT Services",
    "Banking"
  ],
  "Languages": "- English\n- Urdu",
  "Work Experience": "**Data & Analytics Engineer**  \n*Ascend Analytics*  \n*December 2024 \u2013 Present*  \n- Spearheaded the modernization of the data warehouse infrastructure to Azure Cloud, achieving an 80% reduction in operational costs.  \n- Re-architected the Enterprise Data Model, enhancing query performance and scalability.  \n- Designed and implemented an audit logging system in Azure SQL to ensure robust data governance and compliance.  \n- Consolidated datasets using Azure Data Factory, reducing the number of pipelines and improving overall system efficiency.  \n\n**Data Engineer**  \n*Dotlabs*  \n*June 2024 \u2013 Present*  \n- Developed scalable data pipelines to transform JSON streaming data into structured formats, enabling seamless integration for Hopi Housing Service.  \n- Designed and deployed interactive dashboards in Amazon QuickSight, improving data accessibility for stakeholders.  \n- Engineered data transformations using AWS Glue and automated schema handling with weekly crawlers, streamlining data ingestion processes.  \n- Designed and optimized a Redshift data warehouse for Sunderstorm Cannabis Company, significantly improving query performance and analytics capabilities.  \n\n**Data Scientist**  \n*VaporVM*  \n*July 2023 \u2013 June 2024*  \n- Automated complex Excel reporting tasks using Python, reducing processing time and manual effort.  \n- Deployed machine learning models in distributed environments, enabling scalable predictive analytics.  \n- Established and managed a Cloudera cluster to ensure optimal performance for big data processing.  \n- Conducted ETL/ELT operations to support data warehousing and contributed to the creation of an OLAP system for advanced analytics.  \n\n**Data Scientist**  \n*PACRA*  \n*June 2022 \u2013 August 2022*  \n- Developed credit risk models using Python and deep learning algorithms, providing actionable insights for financial risk assessment.  \n- Extracted financial report data using Azure Form Recognizer and streamlined data preparation with Tableau Prep.  \n- Visualized data insights through Google Data Studio and Tableau, enhancing decision-making processes.  \n\n**Data Engineer**  \n*Contract.PK*  \n*August 2022 \u2013 September 2022*  \n- Engineered ETL pipelines using Python to integrate data from SQL and NoSQL databases, ensuring seamless data flow.  \n- Architected an OLAP system with optimized schemas and indexes, improving query performance and analytical capabilities.  \n- Established data consistency and concurrency controls to ensure reliable transaction management across systems.",
  "Education": "**Bachelor of Science in Data Science**, University of California, Berkeley (Graduated: 2018)\n\n**Bachelor of Science in Statistics**, University of Michigan (Graduated: 2016)",
  "Projects": "**1. HR Analytics in Power BI**  \n- Extracted financial report data using Azure Form Recognizer and cleaned datasets with Python and Tableau Prep.  \n- Developed predictive models using deep learning algorithms, reducing manual data entry by 60%.  \n- Designed interactive dashboards in Power BI, enabling stakeholders to derive actionable insights from HR metrics.  \n\n**2. Synapse-to-Fabric Modernization Project**  \n- Spearheaded the migration of data workflows from Azure Synapse to Microsoft Fabric, optimizing data processing pipelines.  \n- Enhanced data governance by implementing robust audit logging and monitoring systems.  \n- Improved query performance and scalability by re-architecting the enterprise data model.  \n\n**3. Lakehouse Architecture with AWS Glue, S3, and Athena**  \n- Designed and implemented a lakehouse architecture, integrating AWS Glue, S3, and Athena for scalable data processing.  \n- Automated schema detection and data transformations using AWS Glue crawlers, ensuring seamless data ingestion.  \n- Enabled real-time analytics by optimizing query execution in Athena.  \n\n**4. Credit Risk Data Engineering Prediction Pipeline**  \n- Engineered ETL pipelines to process financial data for credit risk modeling.  \n- Built predictive models using Python and machine learning algorithms to assess creditworthiness.  \n- Streamlined data workflows, reducing processing time and improving model accuracy.  \n\n**5. Inventory Analysis in Tableau**  \n- Conducted inventory performance analysis using Tableau, identifying trends and inefficiencies.  \n- Visualized key metrics with interactive dashboards, enabling data-driven decision-making for inventory management.  \n- Leveraged SQL and Python for data extraction and preprocessing.  \n\n**6. Intelligent Agent Deployment with Reasoning in Vertex AI**  \n- Deployed intelligent agents in Vertex AI, enabling automated reasoning and decision-making capabilities.  \n- Integrated machine learning models to enhance the accuracy of agent predictions.  \n- Optimized workflows for real-time data processing and analysis.  \n\n**7. Dynamic Malware Analysis Using ML**  \n- Developed machine learning models to analyze and classify malware dynamically.  \n- Automated feature extraction from malware datasets, improving detection accuracy.  \n- Utilized Python and R for data preprocessing and model development.  \n\n**8. Middilion Data Architecture in Azure Synapse**  \n- Designed a scalable data architecture in Azure Synapse, consolidating disparate datasets.  \n- Improved data accessibility and query performance through optimized indexing and partitioning.  \n- Established robust ETL pipelines for seamless data integration.",
  "TAILORING_SCORE": "9 / 10"
}